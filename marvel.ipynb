import pandas as pd 
import requests
from bs4 import BeautifulSoup
import re

def clean_movie_data(movies_df):
    movies_df['producer'] = movies_df['producer'].fillna(method='ffill')
    movies_df['status'] = movies_df['status'].fillna(method='ffill')
    
    def remove_references(text):
        return re.sub(r'\s*\[\s*\d+\s*\]', '', text)
    
    # Apply the cleaning function to all string cells
    movies_df_cleaned = movies_df.applymap(lambda cell: remove_references(cell) if isinstance(cell, str) else cell)
    
    # Extract and format release date
    movies_df_cleaned['release_date'] = pd.to_datetime(
        movies_df_cleaned['release_date'].str.extract(r'\((.*?)\)')[0], errors='coerce'
    )
    movies_df_cleaned['release_date'] = movies_df_cleaned['release_date'].dt.strftime('%Y-%m-%d')
    
    # Return or print the cleaned DataFrame
    return movies_df_cleaned

    def scrape_characters_data():
    url = "https://en.wikipedia.org/wiki/List_of_Marvel_Cinematic_Universe_films"
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')

    # Print all captions to check exact caption text
    for tbl in soup.find_all('table', class_='wikitable'):
        caption = tbl.find('caption')
        if caption:
            print(f"Caption: {caption.get_text(strip=True)}")

scrape_characters_data()
def scrape_characters_data():
    url = "https://en.wikipedia.org/wiki/List_of_Marvel_Cinematic_Universe_films"
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')
    table = None
    
    # Iterate through tables and match a part of the caption
    for tbl in soup.find_all('table', class_='wikitable'):
        caption = tbl.find('caption')
        if caption and "Recurring cast" in caption.get_text():
            table = tbl
            break

    if table:
        headers = [th.get_text(strip=True) for th in table.find_all('tr')[0].find_all('th')]
        rows = []
        
        for tr in table.find_all('tr')[1:]:
            row = []
            for td in tr.find_all(['th', 'td']):
                colspan = td.get('colspan')
                if colspan:
                    colspan = int(colspan)
                    row.extend([td.get_text(separator=" ", strip=True)] * colspan)
                else:
                    row.append(td.get_text(separator=" ", strip=True))

            # Fill or trim to match the number of headers
            while len(row) < len(headers):
                row.append(None)
            if len(row) > len(headers):
                row = row[:len(headers)]
            
            rows.append(row)

        # Create and return DataFrame
        return pd.DataFrame(rows, columns=headers)
    else:
        print("⚠️ Table with specified caption not found.")
        return pd.DataFrame()

# Call the function and check the result
characters_df = scrape_characters_data()
print(characters_df.head())

def fetch_omdb_data(film_name):
    url = f'http://www.omdbapi.com/?t={film_name}&apikey={OMDB_API_KEY}'
    response = requests.get(url)
    if response.status_code == 200:
        return response.json()
    else:
        return {"Title": film_name, "Error": "Data not found"}
